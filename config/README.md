# Configuration

This section illustrates the meaning of variables in the configuration file.

For exemplar selection, currently we support `herding`, `random` and `loss` schemes.

For regularization, currently we support `l2`, `dropout` and `ewc` schemes.

We also provide a default configuration in `config.cfg`, which contains the settings for **sclstm** based model with 250 fixed size exemplars generated by **prioritized (loss)** selection schemes and **ewc** regularization trained and test on **domain** wise tasks. 

## EXPERIMENT

- `experiment_prefix` The path to store the experiment's model and results
- `exemplar_selection` The available schemes for exemplar selection.
- `experiment` The name of experiment. It is recommended to follow the naming convention below: 

    -   **finetune mode** `finetune`
    -   **upper bound mode** `upper_bound`
    -   **exemplar mode without regularization** `exemplar_{exemplar_selection_scheme}_{exemplar_size}`
    -   **exemplar mode with regularization** `exemplar_{regularization_scheme}_{exemplar_selection_scheme}_{exemplar_size}`

## DATA
This block specifies the properties related to dataset. It is recommended to use the default settings.

- `vocab_file` vocabulary file
- `feat_file` feature file (./resource/woz3/feat_unique_do/da.json)
- `text_file` text file (./resource/woz3/text_unique_do/da.json)
- `template_file` file containing all the domains, dialogue acts and slot values
- `data_split` dataset file (./resource/woz3/data_split/all_unique_do/da_datasplit.json)
- `shuffle` whether shuffle data during training and evaluation
- `batch_size` batch size
- `granularity` the granularity of task of continual learning, 0 indicates domain wise task and 1 indicates dialogue act wise task
- `sent_max_len` whether pad sentences to same length
- `task_seq` sequence of task id to train and evaluate

## MODEL
This block specifies some hyperparameters of the model.

- `model_type` model type, either `lm` for sclstm or `cvae` for scvae

    The following variables are recommended to be used with default settings.

- `dec_type` decoder type
- `train_percentage` percentage of training data to use 
- `num_layer` number of layer in decoder
- `hidden_size` latent size of the model
- `clip` clipping regularization parameter

## TRAINING
This block specifies some hyperparameters of training. It is recommended to use the default settings.
- `n_epochs` number of epochs
- `save_exemplars` whether save exemplars or not

## TESTING 
This block specifies some settings during testing. It is recommended to use the default settings.

- `beam_size` size of beam search
- `output_log` whether output generated sentences to log or not

## EXEMPLARS
This block specifies some hyperparameters of exemplars.

- `exemplar_size` number of exemplars to keep
- `fixed_size_exemplar` whether fix the total number of exemplar to be `exemplar_size` or have  `exemplar_size` exemplars per task
