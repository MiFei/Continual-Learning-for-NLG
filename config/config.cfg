[EXPERIMENT]
experiment_prefix = ./experiments/domain/

# Examplar selection scheme
exemplar_selection = herding,random,loss

# Experiment type
experiment = exemplar_ewc_loss_250

[DATA]
# Default settings
text_dir =		./data/woz3/text/
label_dir =	    ./data/woz3/acts/
vocab_file =	./resource/woz3/vocab.txt
feat_file =		./resource/woz3/feat_unique_do.json
text_file =		./resource/woz3/text_unique_do.json
template_file =	./resource/woz3/template.txt
data_split = ./resource/woz3/data_split/all_unique_do_datasplit.json
shuffle = true
batch_size = 128

# 0->Domain wise, 1->Dialogue act wise, default to 0
granularity = 0
# Set max sent length to 60
sent_max_len = true

# sequence of task ids to train and evaluate; modifiable if you want to test other sequence
# use 1,7,0,6,4,2,8 for our da experiement in Sec 4.6
task_seq = 0,5,2,1,3,4

[MODEL]
# Model can be either lm (the basic SCLSTM) or cvae
model_type = lm 
  
# Decoder can only be sclstm
dec_type = sclstm                  
train_percentage = 1

num_layer = 1
hidden_size = 128
clip = 0.5

# Settings for cvae

# Std for cvae latent vector sampling gaussian
std = 1        

# CVAE KL annealing slow start parameter
full_kl_step = 5000                 
latent_size = 128        

[TRAINING]
n_epochs = 100

# whether to save exemplars
save_exemplars = true

[TESTING]
beam_size = 1
# whether to output generated sentences to log
output_log = False

[EXEMPLARS]
exemplar_size = 250
fixed_size_exemplar = True

